{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# DREAM advanced data reduction\n",
    "\n",
    "- Audience: Instrument (data) scientists, instrument users\n",
    "- Prerequisites: Basic knowledge of [Scipp](https://scipp.github.io/), [Sciline](https://scipp.github.io/sciline/)\n",
    "\n",
    "This notebook builds on the [basic powder workflow](./dream-powder-reduction.rst) and demonstrates how the workflow can be used to compute different results and how alternative steps can be used.\n",
    "\n",
    "This notebook uses the same data as the basic notebook, a McStas + GEANT4 simulation.\n",
    "The data is available through the ESSdiffraction package but accessing it requires the `pooch` package.\n",
    "If you get an error about a missing module `pooch`, you can install it with `!pip install pooch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipp as sc\n",
    "from ess import dream, powder\n",
    "import ess.dream.data  # noqa: F401\n",
    "from ess.powder.types import *\n",
    "import pandas as pd\n",
    "import plopp as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Compute intensity as a function of scattering angle\n",
    "\n",
    "The basic notebook sums over all detector voxels and produces a 1D curve.\n",
    "Here, we instead bin by scattering angle $2\\theta$.\n",
    "\n",
    "First, define the same workflow as in the [basic example](./dream-powder-reduction.rst#create_and_configure_the_workfow):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = dream.DreamGeant4Workflow(run_norm=powder.RunNormalization.monitor_histogram)\n",
    "\n",
    "workflow[Filename[SampleRun]] = dream.data.simulated_diamond_sample()\n",
    "workflow[Filename[VanadiumRun]] = dream.data.simulated_vanadium_sample()\n",
    "workflow[Filename[BackgroundRun]] = dream.data.simulated_empty_can()\n",
    "workflow[CalibrationFilename] = None\n",
    "\n",
    "workflow[MonitorFilename[SampleRun]] = dream.data.simulated_monitor_diamond_sample()\n",
    "workflow[MonitorFilename[VanadiumRun]] = dream.data.simulated_monitor_vanadium_sample()\n",
    "workflow[MonitorFilename[BackgroundRun]] = dream.data.simulated_monitor_empty_can()\n",
    "workflow[CaveMonitorPosition] = sc.vector([0.0, 0.0, -4220.0], unit=\"mm\")\n",
    "\n",
    "workflow[dream.InstrumentConfiguration] = dream.InstrumentConfiguration.high_flux\n",
    "# Select a detector bank:\n",
    "workflow[NeXusDetectorName] = \"mantle\"\n",
    "# We drop uncertainties where they would otherwise lead to correlations:\n",
    "workflow[UncertaintyBroadcastMode] = UncertaintyBroadcastMode.drop\n",
    "# Edges for binning in d-spacing:\n",
    "workflow[DspacingBins] = sc.linspace(\"dspacing\", 0.3, 2.3434, 201, unit=\"angstrom\")\n",
    "\n",
    "# Do not mask any pixels / voxels:\n",
    "workflow = powder.with_pixel_mask_filenames(workflow, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "And then add the desired bin edges for $2\\theta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[TwoThetaBins] = sc.linspace(\n",
    "    dim=\"two_theta\", unit=\"rad\", start=0.8, stop=2.4, num=201\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Instead of computing `IofDspacing` and from that `IofTof` as in the basic example, here, we want to compute `IofDspacingTwoTheta`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.visualize(IofDspacingTwoTheta, graph_attr={\"rankdir\": \"LR\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Now we can compute the intensity as a function of $2\\theta$ and $d$-spacing by requesting `IofDspacingTwoTheta`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dspacing = workflow.compute(IofDspacingTwoTheta)\n",
    "grouped_dspacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dspacing.hist().plot(title=grouped_dspacing.coords['detector'].value.capitalize(),\n",
    "                             norm=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Alternative run normalizations\n",
    "\n",
    "The [basic example](./dream-powder-reduction.rst) normalizes the detector data by a monitor that was histogrammed in wavelength.\n",
    "ESSdiffraction provides some alternatives.\n",
    "\n",
    "### Normalize by integrated monitor\n",
    "\n",
    "Instead of computing a histogram of the monitor data, we can integrate over all bins to get a single intensity value for the monitor.\n",
    "\n",
    "To do so, specify `ess.powder.RunNormalization.monitor_integrated` when constructing the workflow.\n",
    "This will insert [normalize_by_monitor_integrated](../../generated/modules/ess.powder.correction.normalize_by_monitor_integrated.rst) into the workflow.\n",
    "Then, set parameter as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = dream.DreamGeant4Workflow(run_norm=powder.RunNormalization.monitor_integrated)\n",
    "\n",
    "workflow[Filename[SampleRun]] = dream.data.simulated_diamond_sample()\n",
    "workflow[Filename[VanadiumRun]] = dream.data.simulated_vanadium_sample()\n",
    "workflow[Filename[BackgroundRun]] = dream.data.simulated_empty_can()\n",
    "workflow[CalibrationFilename] = None\n",
    "\n",
    "workflow[MonitorFilename[SampleRun]] = dream.data.simulated_monitor_diamond_sample()\n",
    "workflow[MonitorFilename[VanadiumRun]] = dream.data.simulated_monitor_vanadium_sample()\n",
    "workflow[MonitorFilename[BackgroundRun]] = dream.data.simulated_monitor_empty_can()\n",
    "workflow[CaveMonitorPosition] = sc.vector([0.0, 0.0, -4220.0], unit=\"mm\")\n",
    "\n",
    "workflow[dream.InstrumentConfiguration] = dream.InstrumentConfiguration.high_flux\n",
    "# Select a detector bank:\n",
    "workflow[NeXusDetectorName] = \"mantle\"\n",
    "# We drop uncertainties where they would otherwise lead to correlations:\n",
    "workflow[UncertaintyBroadcastMode] = UncertaintyBroadcastMode.drop\n",
    "# Edges for binning in d-spacing:\n",
    "workflow[DspacingBins] = sc.linspace(\"dspacing\", 0.3, 2.3434, 201, unit=\"angstrom\")\n",
    "\n",
    "# Do not mask any pixels / voxels:\n",
    "workflow = powder.with_pixel_mask_filenames(workflow, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Looking at the graph, we can see that this only differs from the histogrammed monitor normalization in how `NormalizedRunData` is computed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.visualize(IofDspacing, graph_attr={\"rankdir\": \"LR\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "And compute the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = workflow.compute(IofDspacing)\n",
    "result.hist().plot(title=result.coords['detector'].value.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Normalize by proton charge\n",
    "\n",
    "We can normalize the detector data by the accumulated proton charge.\n",
    "This works similarly to normalizing by a monitor, but we pass `ess.powder.RunNormalization.proton_charge` when building the workflow.\n",
    "This will insert [normalize_by_proton_charge](../../generated/modules/ess.powder.correction.normalize_by_proton_charge.rst) into the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = dream.DreamGeant4Workflow(run_norm=powder.RunNormalization.proton_charge)\n",
    "\n",
    "workflow[Filename[SampleRun]] = dream.data.simulated_diamond_sample()\n",
    "workflow[Filename[VanadiumRun]] = dream.data.simulated_vanadium_sample()\n",
    "workflow[Filename[BackgroundRun]] = dream.data.simulated_empty_can()\n",
    "workflow[CalibrationFilename] = None\n",
    "\n",
    "workflow[dream.InstrumentConfiguration] = dream.InstrumentConfiguration.high_flux\n",
    "# Select a detector bank:\n",
    "workflow[NeXusDetectorName] = \"mantle\"\n",
    "# We drop uncertainties where they would otherwise lead to correlations:\n",
    "workflow[UncertaintyBroadcastMode] = UncertaintyBroadcastMode.drop\n",
    "# Edges for binning in d-spacing:\n",
    "workflow[DspacingBins] = sc.linspace(\"dspacing\", 0.3, 2.3434, 201, unit=\"angstrom\")\n",
    "\n",
    "# Do not mask any pixels / voxels:\n",
    "workflow = powder.with_pixel_mask_filenames(workflow, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Looking at the graph, we can see that this differs from the monitor normalizations in how `NormalizedRunData` is computed.\n",
    "And since we don't need them here, the monitor providers and parameters are not in the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.visualize(IofDspacing, graph_attr={\"rankdir\": \"LR\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "And compute the result as normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = workflow.compute(IofDspacing)\n",
    "result.hist().plot(title=result.coords['detector'].value.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Compute intermediate results\n",
    "\n",
    "For inspection and debugging purposes, we can also compute intermediate results.\n",
    "To avoid repeated computation (including costly loading of files), we can request multiple results at once, including the final result, if desired.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediates = workflow.compute(\n",
    "    (\n",
    "        DataWithScatteringCoordinates[SampleRun],\n",
    "        MaskedData[SampleRun],\n",
    "    )\n",
    ")\n",
    "\n",
    "intermediates[DataWithScatteringCoordinates[SampleRun]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_theta = sc.linspace(\"two_theta\", 0.8, 2.4, 301, unit=\"rad\")\n",
    "intermediates[MaskedData[SampleRun]].hist(\n",
    "    two_theta=two_theta, wavelength=300\n",
    ").plot(norm=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Process all detector banks\n",
    "\n",
    "The other sections only use a single detector bank.\n",
    "In practice, we want to process all banks.\n",
    "This section demonstrates how to do this, except for the sans detector which requires a different workflow.\n",
    "\n",
    "We construct the workflow as before but this time **without specifying a detector name**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = dream.DreamGeant4Workflow(run_norm=powder.RunNormalization.proton_charge)\n",
    "\n",
    "workflow[Filename[SampleRun]] = dream.data.simulated_diamond_sample()\n",
    "workflow[Filename[VanadiumRun]] = dream.data.simulated_vanadium_sample()\n",
    "workflow[Filename[BackgroundRun]] = dream.data.simulated_empty_can()\n",
    "workflow[CalibrationFilename] = None\n",
    "\n",
    "workflow[dream.InstrumentConfiguration] = dream.InstrumentConfiguration.high_flux\n",
    "# We drop uncertainties where they would otherwise lead to correlations:\n",
    "workflow[UncertaintyBroadcastMode] = UncertaintyBroadcastMode.drop\n",
    "# Edges for binning in d-spacing:\n",
    "workflow[DspacingBins] = sc.linspace(\"dspacing\", 0.3, 2.3434, 201, unit=\"angstrom\")\n",
    "\n",
    "# Do not mask any pixels / voxels:\n",
    "workflow = powder.with_pixel_mask_filenames(workflow, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "At this point, the workflow is incomplete because it is missing the `NexusDetectorName` parameter.\n",
    "This will be fixed below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### 1D intensity vs. ToF\n",
    "\n",
    "Now, we build a parameter table (as a [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)) with the desired detector names.\n",
    "(Note that we could use a simple `dict` as well if Pandas was not available.)\n",
    "Then we [map](https://scipp.github.io/sciline/user-guide/parameter-tables.html) the workflow over those detector names to apply the workflow to each bank separately.\n",
    "We could do this at some intermediate step, but it is easiest to map the final result.\n",
    "Finally, we combine the data arrays for the individual detectors into a single data group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_names = [\"mantle\", \"endcap_forward\", \"endcap_backward\", \"high_resolution\"]\n",
    "parameter_table = pd.DataFrame(\n",
    "    {NeXusDetectorName: detector_names},\n",
    "    index=detector_names\n",
    ").rename_axis(index='detector')\n",
    "\n",
    "all_detector_workflow = workflow.copy()\n",
    "mapped = all_detector_workflow[IofDspacing].map(parameter_table)\n",
    "all_detector_workflow[IofDspacing] = mapped.reduce(func=powder.grouping.collect_detectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "The graph shows all domain types that are used separately for each detector bank as a box instead of a flat square:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_detector_workflow.visualize(IofDspacing, graph_attr={\"rankdir\": \"LR\"}, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Now compute the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = all_detector_workflow.compute(IofDspacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "We can plot the detectors individually.\n",
    "(The range covered by the $d$-spacing bins chosen above is too wide for some banks.\n",
    "This leads to some bins containing NaN or INF, which is masked out by the workflow.\n",
    "Here, we set those values to 0 to improve the plot.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms = result.hist()\n",
    "for h in histograms.values():\n",
    "    if 'zero_vanadium' in h.masks:\n",
    "        h.values[h.masks['zero_vanadium'].values] = 0\n",
    "histograms.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### 2D intensity vs. d-spacing and 2θ\n",
    "\n",
    "Just like before, we map the workflow over the detector names.\n",
    "But here we also assign different $2\\theta$ bins for each detector bank.\n",
    "Those bins are chosen arbitrarily here such that they don't overlap.\n",
    "This will simplify later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_names = [\"mantle\", \"endcap_forward\", \"endcap_backward\", \"high_resolution\"]\n",
    "two_theta_bins = [\n",
    "    sc.linspace(dim=\"two_theta\", unit=\"rad\", start=0.77, stop=2.36, num=201),\n",
    "    sc.linspace(dim=\"two_theta\", unit=\"rad\", start=0.24, stop=0.71, num=101),\n",
    "    sc.linspace(dim=\"two_theta\", unit=\"rad\", start=2.42, stop=2.91, num=151),\n",
    "    sc.linspace(dim=\"two_theta\", unit=\"rad\", start=2.91, stop=3.11, num=51),\n",
    "]\n",
    "parameter_table = pd.DataFrame(\n",
    "    {NeXusDetectorName: detector_names,\n",
    "     TwoThetaBins: two_theta_bins,\n",
    "     },\n",
    "    index=detector_names\n",
    ").rename_axis(index='detector')\n",
    "\n",
    "all_detector_workflow = workflow.copy()\n",
    "mapped = all_detector_workflow[IofDspacingTwoTheta].map(parameter_table)\n",
    "all_detector_workflow[IofDspacingTwoTheta] = mapped.reduce(func=powder.grouping.collect_detectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_detector_workflow.visualize(IofDspacing, graph_attr={\"rankdir\": \"LR\"}, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = all_detector_workflow.compute(IofDspacingTwoTheta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "We can 'sum' over $2\\theta$ by using `concat` to obtain a 1D curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(da.bins.concat('two_theta').hist() for da in result.values()).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "But we can also preserve the $2\\theta$ dimension to produce a 2D plot.\n",
    "Since the detector banks have different, non-overlapping, $2\\theta$ ranges, we can simply plot all data arrays into a single figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.imagefigure(*(pp.Node(da.hist()) for da in result.values()), norm='log', cbar=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
