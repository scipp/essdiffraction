{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# DREAM advanced data reduction\n",
    "\n",
    "- Audience: Instrument (data) scientists, instrument users\n",
    "- Prerequisites: Basic knowledge of [Scipp](https://scipp.github.io/), [Sciline](https://scipp.github.io/sciline/)\n",
    "\n",
    "This notebook builds on the [basic powder workflow](./dream-data-reduction.rst) and demonstrates how the workflow can be used to compute different results and how alternative steps can be used.\n",
    "\n",
    "This notebook uses the same data as the basic notebook, a McStas + GEANT4 simulation.\n",
    "The data is available through the ESSdiffraction package but accessing it requires the `pooch` package.\n",
    "If you get an error about a missing module `pooch`, you can install it with `!pip install pooch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipp as sc\n",
    "from ess import dream, powder\n",
    "import ess.dream.data  # noqa: F401\n",
    "from ess.powder.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Compute intensity as a function of scattering angle\n",
    "\n",
    "The basic notebook sums over all detector voxels and produces a 1D curve.\n",
    "Here, we instead bin by scattering angle $2\\theta$.\n",
    "\n",
    "First, define the same workflow as in the [basic example](./dream-data-reduction.rst#create_and_configure_the_workfow):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = dream.DreamGeant4Workflow(run_norm=powder.RunNormalization.monitor_histogram)\n",
    "\n",
    "workflow[Filename[SampleRun]] = dream.data.simulated_diamond_sample()\n",
    "workflow[Filename[VanadiumRun]] = dream.data.simulated_vanadium_sample()\n",
    "workflow[Filename[BackgroundRun]] = dream.data.simulated_empty_can()\n",
    "workflow[CalibrationFilename] = None\n",
    "\n",
    "workflow[MonitorFilename[SampleRun]] = dream.data.simulated_monitor_diamond_sample()\n",
    "workflow[MonitorFilename[VanadiumRun]] = dream.data.simulated_monitor_vanadium_sample()\n",
    "workflow[MonitorFilename[BackgroundRun]] = dream.data.simulated_monitor_empty_can()\n",
    "workflow[CaveMonitorPosition] = sc.vector([0.0, 0.0, -4220.0], unit=\"mm\")\n",
    "\n",
    "workflow[dream.InstrumentConfiguration] = dream.InstrumentConfiguration.high_flux\n",
    "# Select a detector bank:\n",
    "workflow[NeXusDetectorName] = \"mantle\"\n",
    "# We drop uncertainties where they would otherwise lead to correlations:\n",
    "workflow[UncertaintyBroadcastMode] = UncertaintyBroadcastMode.drop\n",
    "# Edges for binning in d-spacing:\n",
    "workflow[DspacingBins] = sc.linspace(\"dspacing\", 0.3, 2.3434, 201, unit=\"angstrom\")\n",
    "\n",
    "# Do not mask any pixels / voxels:\n",
    "workflow = powder.with_pixel_mask_filenames(workflow, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "And then add the desired bin edges for $2\\theta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[TwoThetaBins] = sc.linspace(\n",
    "    dim=\"two_theta\", unit=\"rad\", start=0.8, stop=2.4, num=201\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Now we can compute the intensity as a function of $2\\theta$ and $d$-spacing by requesting `IofDspacingTwoTheta`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dspacing = workflow.compute(IofDspacingTwoTheta)\n",
    "grouped_dspacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dspacing.hist().plot(norm=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Alternative run normalizations\n",
    "\n",
    "The [basic example](./dream-data-reduction.rst) normalizes the detector data by a monitor that was histogrammed in wavelength.\n",
    "ESSdiffraction provides some alternatives.\n",
    "\n",
    "### Normalize by integrated monitor\n",
    "\n",
    "Instead of computing a histogram of the monitor data, we can integrate over all bins to get a single intensity value for the monitor.\n",
    "To do so, specify `ess.powder.RunNormalization.monitor_integrated` when constructing the workflow.\n",
    "This will insert [normalize_by_monitor_integrated](../../generated/modules/ess.powder.correction.normalize_by_monitor_integrated.rst) into the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = dream.DreamGeant4Workflow(run_norm=powder.RunNormalization.monitor_integrated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Then set all parameters as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[Filename[SampleRun]] = dream.data.simulated_diamond_sample()\n",
    "workflow[Filename[VanadiumRun]] = dream.data.simulated_vanadium_sample()\n",
    "workflow[Filename[BackgroundRun]] = dream.data.simulated_empty_can()\n",
    "workflow[CalibrationFilename] = None\n",
    "\n",
    "workflow[MonitorFilename[SampleRun]] = dream.data.simulated_monitor_diamond_sample()\n",
    "workflow[MonitorFilename[VanadiumRun]] = dream.data.simulated_monitor_vanadium_sample()\n",
    "workflow[MonitorFilename[BackgroundRun]] = dream.data.simulated_monitor_empty_can()\n",
    "workflow[CaveMonitorPosition] = sc.vector([0.0, 0.0, -4220.0], unit=\"mm\")\n",
    "\n",
    "workflow[dream.InstrumentConfiguration] = dream.InstrumentConfiguration.high_flux\n",
    "# Select a detector bank:\n",
    "workflow[NeXusDetectorName] = \"mantle\"\n",
    "# We drop uncertainties where they would otherwise lead to correlations:\n",
    "workflow[UncertaintyBroadcastMode] = UncertaintyBroadcastMode.drop\n",
    "# Edges for binning in d-spacing:\n",
    "workflow[DspacingBins] = sc.linspace(\"dspacing\", 0.3, 2.3434, 201, unit=\"angstrom\")\n",
    "\n",
    "# Do not mask any pixels / voxels:\n",
    "workflow = powder.with_pixel_mask_filenames(workflow, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "And compute the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = workflow.compute(IofTof)\n",
    "result.hist().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Normalize by proton charge\n",
    "\n",
    "We can normalize the detector data by the accumulated proton charge.\n",
    "This works similarly to normalizing by a monitor, but we pass `ess.powder.RunNormalization.proton_charge` when building the workflow.\n",
    "This will insert [normalize_by_proton_charge](../../generated/modules/ess.powder.correction.normalize_by_proton_charge.rst) into the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = dream.DreamGeant4Workflow(run_norm=powder.RunNormalization.proton_charge)\n",
    "\n",
    "workflow[Filename[SampleRun]] = dream.data.simulated_diamond_sample()\n",
    "workflow[Filename[VanadiumRun]] = dream.data.simulated_vanadium_sample()\n",
    "workflow[Filename[BackgroundRun]] = dream.data.simulated_empty_can()\n",
    "workflow[CalibrationFilename] = None\n",
    "\n",
    "workflow[dream.InstrumentConfiguration] = dream.InstrumentConfiguration.high_flux\n",
    "# Select a detector bank:\n",
    "workflow[NeXusDetectorName] = \"mantle\"\n",
    "# We drop uncertainties where they would otherwise lead to correlations:\n",
    "workflow[UncertaintyBroadcastMode] = UncertaintyBroadcastMode.drop\n",
    "# Edges for binning in d-spacing:\n",
    "workflow[DspacingBins] = sc.linspace(\"dspacing\", 0.3, 2.3434, 201, unit=\"angstrom\")\n",
    "\n",
    "# Do not mask any pixels / voxels:\n",
    "workflow = powder.with_pixel_mask_filenames(workflow, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "And compute the result as normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = workflow.compute(IofTof)\n",
    "result.hist().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "We can also inspect the workflow graph to see that the proton charge normalization has been inserted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.visualize(IofTof, graph_attr={\"rankdir\": \"LR\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Compute intermediate results\n",
    "\n",
    "For inspection and debugging purposes, we can also compute intermediate results.\n",
    "To avoid repeated computation (including costly loading of files), we can request multiple results at once, including the final result, if desired.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediates = workflow.compute(\n",
    "    (\n",
    "        DataWithScatteringCoordinates[SampleRun],\n",
    "        MaskedData[SampleRun],\n",
    "    )\n",
    ")\n",
    "\n",
    "intermediates[DataWithScatteringCoordinates[SampleRun]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_theta = sc.linspace(\"two_theta\", 0.8, 2.4, 301, unit=\"rad\")\n",
    "intermediates[MaskedData[SampleRun]].hist(\n",
    "    two_theta=two_theta, wavelength=300\n",
    ").plot(norm=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Process all detector banks\n",
    "\n",
    "The other sections only use a single detector bank.\n",
    "In practice, we want to process all banks.\n",
    "This section demonstrates how to do this, except for the sans detector which requires a different workflow.\n",
    "\n",
    "We construct the workflow as before but this time **without specifying a detector name**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = dream.DreamGeant4Workflow(run_norm=powder.RunNormalization.monitor_histogram)\n",
    "\n",
    "workflow[Filename[SampleRun]] = dream.data.simulated_diamond_sample()\n",
    "workflow[Filename[VanadiumRun]] = dream.data.simulated_vanadium_sample()\n",
    "workflow[Filename[BackgroundRun]] = dream.data.simulated_empty_can()\n",
    "workflow[CalibrationFilename] = None\n",
    "\n",
    "workflow[MonitorFilename[SampleRun]] = dream.data.simulated_monitor_diamond_sample()\n",
    "workflow[MonitorFilename[VanadiumRun]] = dream.data.simulated_monitor_vanadium_sample()\n",
    "workflow[MonitorFilename[BackgroundRun]] = dream.data.simulated_monitor_empty_can()\n",
    "workflow[CaveMonitorPosition] = sc.vector([0.0, 0.0, -4220.0], unit=\"mm\")\n",
    "\n",
    "workflow[dream.InstrumentConfiguration] = dream.InstrumentConfiguration.high_flux\n",
    "# We drop uncertainties where they would otherwise lead to correlations:\n",
    "workflow[UncertaintyBroadcastMode] = UncertaintyBroadcastMode.drop\n",
    "# Edges for binning in d-spacing:\n",
    "workflow[DspacingBins] = sc.linspace(\"dspacing\", 0.3, 2.3434, 201, unit=\"angstrom\")\n",
    "\n",
    "# Do not mask any pixels / voxels:\n",
    "workflow = powder.with_pixel_mask_filenames(workflow, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Now, we [map](https://scipp.github.io/sciline/user-guide/parameter-tables.html) the workflow over the desired detector names to apply it to each bank separately.\n",
    "We could do this at some intermediate step, but it is easiest to map the final result.\n",
    "Finally, we stack the data arrays for the individual detectors into a single data array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_names = [\"mantle\", \"endcap_forward\", \"endcap_backward\", \"high_resolution\"]\n",
    "mapped = workflow[IofTof].map({NeXusDetectorName: detector_names})\n",
    "workflow[IofTof] = mapped.reduce(func=powder.grouping.stack_detectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Now compute the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = workflow.compute(IofTof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "We can plot the detectors individually with the help of `sc.collapse`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = sc.DataGroup({\n",
    "    da.coords['detector'].value: da\n",
    "    for da in sc.collapse(result, keep='tof').values()\n",
    "})\n",
    "split.hist().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Or we sum over detector banks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.hist(tof=300).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
