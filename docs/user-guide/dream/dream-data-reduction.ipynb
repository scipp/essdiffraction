{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# DREAM data reduction\n",
    "\n",
    "We begin with relevant imports.\n",
    "We will be using tutorial data downloaded with `pooch`.\n",
    "If you get an error about a missing module `pooch`, you can install it with `!pip install pooch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipp as sc\n",
    "\n",
    "from ess import dream, powder\n",
    "import ess.dream.data  # noqa: F401\n",
    "from ess.powder.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Create and configure the workflow\n",
    "\n",
    "We begin by creating the Dream (Geant4) workflow object which is a skeleton for reducing Dream data, with pre-configured steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = dream.DreamGeant4Workflow(run_norm=powder.RunNormalization.proton_charge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "We then need to set the missing parameters which are specific to each experiment\n",
    "(the keys are types defined in [essdiffraction.powder.types](../generated/modules/ess.diffraction.powder.types.rst)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[Filename[SampleRun]] = dream.data.simulated_diamond_sample()\n",
    "workflow[Filename[VanadiumRun]] = dream.data.simulated_vanadium_sample()\n",
    "workflow[Filename[BackgroundRun]] = dream.data.simulated_empty_can()\n",
    "workflow[CalibrationFilename] = None\n",
    "workflow[NeXusDetectorName] = \"mantle\"\n",
    "# The upper bounds mode is not yet implemented.\n",
    "workflow[UncertaintyBroadcastMode] = UncertaintyBroadcastMode.drop\n",
    "# Edges for binning in d-spacing\n",
    "workflow[DspacingBins] = sc.linspace(\"dspacing\", 0.0, 2.3434, 201, unit=\"angstrom\")\n",
    "# Mask in time-of-flight to crop to valid range\n",
    "workflow[TofMask] = lambda x: (x < sc.scalar(0.0, unit=\"ns\")) | (\n",
    "        x > sc.scalar(86e6, unit=\"ns\")\n",
    ")\n",
    "workflow[TwoThetaMask] = None\n",
    "workflow[WavelengthMask] = None\n",
    "# No pixel masks\n",
    "workflow = powder.with_pixel_mask_filenames(workflow, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Use the workflow\n",
    "\n",
    "We can visualize the graph for computing the final normalized result for intensity as a function of time-of-flight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.visualize([IofTof, ReducedTofCIF], graph_attr={\"rankdir\": \"LR\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "We then call `compute()` to compute the result:\n",
    "(The `cif` object will later be used to write the result to disk.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = workflow.compute([IofTof, ReducedTofCIF])\n",
    "result = results[IofTof]\n",
    "cif_data = results[ReducedTofCIF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram = result.hist()\n",
    "histogram.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "We can now save the result to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cif_data.comment = \"\"\"This file was generated with the DREAM data reduction user guide\n",
    "in the documentation of ESSdiffraction.\n",
    "See https://scipp.github.io/essdiffraction/\n",
    "\"\"\"\n",
    "cif_data.save('reduced.cif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Compute intermediate results\n",
    "\n",
    "For inspection and debugging purposes, we can also compute intermediate results.\n",
    "To avoid repeated computation (including costly loading of files), we can request multiple results at once, including the final result, if desired.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediates = workflow.compute(\n",
    "    (\n",
    "        DataWithScatteringCoordinates[SampleRun],\n",
    "        MaskedData[SampleRun],\n",
    "    )\n",
    ")\n",
    "\n",
    "intermediates[DataWithScatteringCoordinates[SampleRun]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_theta = sc.linspace(\"two_theta\", 0.8, 2.4, 301, unit=\"rad\")\n",
    "intermediates[MaskedData[SampleRun]].hist(two_theta=two_theta, wavelength=300).plot(\n",
    "    norm=\"log\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Grouping by scattering angle\n",
    "\n",
    "The above workflow focuses the data by merging all instrument pixels to produce a 1d d-spacing curve.\n",
    "If instead we want to group into $2\\theta$ bins, we can alter the workflow parameters by adding some binning in $2\\theta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[TwoThetaBins] = sc.linspace(\n",
    "    dim=\"two_theta\", unit=\"rad\", start=0.8, stop=2.4, num=17\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dspacing = workflow.compute(IofDspacingTwoTheta)\n",
    "grouped_dspacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = sc.midpoints(grouped_dspacing.coords[\"two_theta\"])\n",
    "sc.plot(\n",
    "    {\n",
    "        f\"{angle[group].value:.3f} {angle[group].unit}\": grouped_dspacing[\n",
    "            \"two_theta\", group\n",
    "        ].hist()\n",
    "        for group in range(2, 6)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dspacing.hist().plot(norm=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "##  Normalizing by monitor\n",
    "\n",
    "The workflow used above normalizes the detected counts by proton charge.\n",
    "Alternatively, ESSdiffraction can normalize by a monitor.\n",
    "In this example, this is DREAM's cave monitor.\n",
    "\n",
    "There are two options for normalizing by monitor:\n",
    "1. Normalize by a wavelength-histogram of the monitor counts ([normalize_by_monitor_histogram](../../generated/modules/ess.powder.correction.normalize_by_monitor_histogram.rst)).\n",
    "2. Normalized by the integral over all wavelength bins ([normalize_by_monitor_integrated](../../generated/modules/ess.powder.correction.normalize_by_monitor_integrated.rst)).\n",
    "\n",
    "Here, we use option 1.\n",
    "Option 2 can be chosen by constructing a workflow using `run_norm=powder.RunNormalization.monitor_integrated`.\n",
    "\n",
    "Construct a workflow as before but select normalization by monitor histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = dream.DreamGeant4Workflow(run_norm=powder.RunNormalization.monitor_histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "In addition to the parameters used before, we also need to provide filenames for monitor data and a position of the monitor as that is not saved in the simulation files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[MonitorFilename[SampleRun]] = dream.data.simulated_monitor_diamond_sample()\n",
    "workflow[MonitorFilename[VanadiumRun]] = dream.data.simulated_monitor_vanadium_sample()\n",
    "workflow[MonitorFilename[BackgroundRun]] = dream.data.simulated_monitor_empty_can()\n",
    "workflow[CaveMonitorPosition] = sc.vector([0.0, 0.0, -4220.0], unit='mm')\n",
    "\n",
    "# These are the same as at the top of the notebook:\n",
    "workflow[Filename[SampleRun]] = dream.data.simulated_diamond_sample()\n",
    "workflow[Filename[VanadiumRun]] = dream.data.simulated_vanadium_sample()\n",
    "workflow[Filename[BackgroundRun]] = dream.data.simulated_empty_can()\n",
    "workflow[CalibrationFilename] = None\n",
    "workflow[NeXusDetectorName] = \"mantle\"\n",
    "workflow[UncertaintyBroadcastMode] = UncertaintyBroadcastMode.drop\n",
    "workflow[DspacingBins] = sc.linspace(\"dspacing\", 0.0, 2.3434, 201, unit=\"angstrom\")\n",
    "workflow[TofMask] = lambda x: (x < sc.scalar(0.0, unit=\"ns\")) | (\n",
    "        x > sc.scalar(86e6, unit=\"ns\")\n",
    ")\n",
    "workflow[TwoThetaMask] = None\n",
    "workflow[WavelengthMask] = None\n",
    "workflow = powder.with_pixel_mask_filenames(workflow, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.visualize(IofTof, graph_attr={\"rankdir\": \"LR\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = workflow.compute((IofTof, WavelengthMonitor[SampleRun, CaveMonitor]))\n",
    "normalized_by_monitor = results[IofTof]\n",
    "monitor = results[WavelengthMonitor[SampleRun, CaveMonitor]]\n",
    "monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Comparing the final, normalized result shows that it agrees with the data that was normalized by proton-charge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.plot({\n",
    "    'By proton charge': histogram,\n",
    "    'By monitor': normalized_by_monitor.hist()\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
